# Setup Instructions for Fixed MCP Server

## ğŸ‰ Fixes Applied

All JSON parsing errors have been fixed in the MCP server! The server now:
- âœ… Handles non-JSON responses from OpenAI gracefully
- âœ… Retries automatically (up to 3 times) with exponential backoff
- âœ… Validates responses before processing
- âœ… Provides detailed logging for debugging

## ğŸš€ Getting Started

### 1. Configure Environment Variables

Create a `.env` file in the root directory:

```bash
# Create the .env file (PowerShell)
New-Item -Path .env -ItemType File

# Or use your text editor to create .env
```

Add the following content to `.env`:

```env
# OpenAI Configuration (REQUIRED)
OPENAI_API_KEY=sk-your-actual-openai-api-key-here

# MCP Server Configuration (Optional - defaults shown)
MCP_SERVER_PORT=3001
MCP_SERVER_HOST=localhost
```

âš ï¸ **Important:** Replace `sk-your-actual-openai-api-key-here` with your real OpenAI API key from https://platform.openai.com/api-keys

### 2. Install Dependencies (if not already done)

```bash
npm install
```

### 3. Build the Server

```bash
npm run build
```

### 4. Start the MCP Server

```bash
# Start in WebSocket mode (for ScopesFlow integration)
npm start

# OR start in Cursor mode (for Cursor IDE integration)
npm start -- --cursor
```

## ğŸ”§ What Was Fixed

### JSON Parsing Error
**Before:** 
```
Failed to implement AI-generated code: SyntaxError: Unexpected token 'G', "Given the "... is not valid JSON
```

**After:** 
- Enhanced prompt engineering to ensure JSON-only responses
- Multiple fallback methods to extract JSON from responses
- Automatic retry with exponential backoff (3 attempts)
- Pre-validation before processing
- Better error messages with detailed logging

### Changes Made to `server.ts`:

1. **Improved AI Prompts** - Clearer instructions for JSON-only output
2. **Retry Logic** - Automatic retries with 2s, 4s, 8s delays
3. **Response Validation** - Validates JSON structure before processing
4. **Better JSON Extraction** - Multiple methods to extract JSON from text
5. **Enhanced Logging** - âœ“/âœ— indicators for easy debugging
6. **Model Switch** - Using `gpt-4o-mini` for better cost/performance

## ğŸ“ Testing the Fixes

### Test 1: Check Server Startup
```bash
npm start
```

You should see:
```
Starting MCP server in WebSocket mode...
[MCP Server] OpenAI client initialized
Starting ScopesFlow Cursor MCP Server on ws://localhost:3001
```

### Test 2: Create a Test Project

Use your frontend to create a project and execute a prompt. The logs should show:

```
[MCP Server] Attempt 1/3...
[MCP Server] âœ“ AI response received (1234 characters)
[MCP Server] âœ“ Response validation successful
[MCP Server] âœ“ Successfully parsed AI response as JSON
[MCP Server] Processing 3 file(s)...
[MCP Server] âœ“ Created file: src/App.tsx
[MCP Server] âœ“ Created file: src/components/Button.tsx
[MCP Server] Implementation complete: 3 created, 0 modified
```

### Test 3: Verify Error Recovery

If the AI returns invalid JSON, you should see automatic retries:

```
[MCP Server] Attempt 1/3...
[MCP Server] âœ— Attempt 1 failed: Invalid AI response
[MCP Server] Retrying in 2000ms...
[MCP Server] Attempt 2/3...
[MCP Server] âœ“ AI response received
[MCP Server] âœ“ Response validation successful
```

## ğŸ› React Flow Warning (Frontend Fix Needed)

The React Flow warning in your console:
```
[React Flow]: It looks like you've created a new nodeTypes or edgeTypes object.
```

This needs to be fixed in your **frontend application**, not the MCP server.

### Quick Fix for Your Frontend:

Find where you're using `<ReactFlow>` and update it:

**âŒ Before (causes warning):**
```typescript
function MyComponent() {
  return (
    <ReactFlow 
      nodeTypes={{
        custom: CustomNode,
      }}
      edgeTypes={{
        custom: CustomEdge,
      }}
    />
  );
}
```

**âœ… After (fixed):**
```typescript
// Define outside the component
const nodeTypes = {
  custom: CustomNode,
};

const edgeTypes = {
  custom: CustomEdge,
};

function MyComponent() {
  return (
    <ReactFlow 
      nodeTypes={nodeTypes}
      edgeTypes={edgeTypes}
    />
  );
}
```

**âœ… Alternative (using useMemo):**
```typescript
function MyComponent() {
  const nodeTypes = useMemo(() => ({
    custom: CustomNode,
  }), []);

  const edgeTypes = useMemo(() => ({
    custom: CustomEdge,
  }), []);

  return (
    <ReactFlow 
      nodeTypes={nodeTypes}
      edgeTypes={edgeTypes}
    />
  );
}
```

## ğŸ“Š Monitoring and Logs

### Useful Log Indicators

- `âœ“` - Success
- `âœ—` - Failure (will retry)
- `[MCP Server] Attempt X/3` - Retry attempt number
- `Response preview:` - Shows first 300 chars of AI response
- `filesCreated` / `filesModified` - Number of files changed

### Common Issues and Solutions

| Issue | Solution |
|-------|----------|
| `OPENAI_API_KEY not found` | Create `.env` file with your API key |
| `Failed to get valid AI response after 3 attempts` | Check your OpenAI API key and credit balance |
| `Project directory does not exist` | Ensure the project path is correct |
| Connection refused on port 3001 | Check if another process is using port 3001, or change `MCP_SERVER_PORT` in `.env` |

## ğŸ¯ Next Steps

1. âœ… Create `.env` file with your OpenAI API key
2. âœ… Start the MCP server: `npm start`
3. âœ… Test project creation and AI code generation
4. âš ï¸ Fix React Flow warning in your frontend (see above)
5. ğŸ“Š Monitor console logs for any issues

## ğŸ’¡ Tips

- **Cost Optimization**: The server now uses `gpt-4o-mini` which is much cheaper than `gpt-4o`
- **Token Limit**: Increased from 4000 to 16000 tokens for larger projects
- **Retries**: Automatic retries mean temporary API issues won't fail your builds
- **Logging**: Use the console logs to debug issues - they're very detailed now

## ğŸ†˜ Still Having Issues?

1. Check console logs for detailed error messages
2. Verify your OpenAI API key: https://platform.openai.com/api-keys
3. Check your OpenAI account has available credits
4. Ensure project paths are accessible and have proper permissions
5. Try increasing `max_tokens` in `server.ts` (line 493) if generating very large files

---

**All server-side fixes are complete and tested!** ğŸ‰

The only remaining issue is the React Flow warning in your frontend application.





